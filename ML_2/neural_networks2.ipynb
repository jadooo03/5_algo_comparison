{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import copy\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = pd.read_csv('census-income.data.csv')\n",
    "df2 = pd.read_csv('census-income.test.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def determine_type_of_feature(df):\n",
    "    feature_types = []\n",
    "    n_unique_values_threshold = 15\n",
    "\n",
    "    for column in df.columns:\n",
    "        unique_values = df[column].unique()\n",
    "        example_value = unique_values[0]\n",
    "\n",
    "        if (isinstance(example_value, str)) or (len(unique_values) <= n_unique_values_threshold):\n",
    "            feature_types.append(\"Discrete\")\n",
    "        else:\n",
    "            feature_types.append(\"Continuous\")\n",
    "    \n",
    "    return feature_types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "global FEATURE_TYPES\n",
    "FEATURE_TYPES = determine_type_of_feature(df1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def missing_values(df):\n",
    "    c=0\n",
    "    for i in df.columns:\n",
    "        x,count_missing = np.unique(df[i].eq('?'),return_counts=True)\n",
    "        if len(x)==2:\n",
    "            print(i,\"-\",FEATURE_TYPES[c],\"-\",count_missing[1])\n",
    "        # elif len(x)==1 and x[0] == False:\n",
    "        #     print(i,\"-\",FEATURE_TYPES[c],\"- 0\",)\n",
    "        c+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fill_values(df):\n",
    "    #Since all columns are having the discrete value. We replace it with the missing values with the modes, i.e. the highest appearing value\n",
    "    mode_workclass = df.workclass.mode()[0]\n",
    "    mode_occupation = df.occupation.mode()[0]\n",
    "    mode_native_countr = df.native_countr.mode()[0]\n",
    "\n",
    "    #Filling the train and test data with the modes of missing values as they are discrete\n",
    "    df.workclass = df.workclass.replace('?', mode_workclass)\n",
    "    df.occupation = df.occupation.replace('?', mode_occupation)\n",
    "    df.native_countr = df.native_countr.replace('?', mode_native_countr)\n",
    "    missing_values(df)#No missing values\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2['label'] = df2['label'].str.replace('.', '')\n",
    "missing_values(df1)\n",
    "missing_values(df2)\n",
    "fill_values(df1)\n",
    "fill_values(df2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_test_split(df,test_size):\n",
    "    #checks whether the test_size is a proportion of the total number of samples\n",
    "    if isinstance(test_size,float): \n",
    "        test_size = round(test_size*len(df))\n",
    "\n",
    "    #store random samples in the test and training data\n",
    "    indices = df.index.tolist()\n",
    "    test_indices = random.sample(population=indices, k = test_size)\n",
    "\n",
    "    #random data points from sample sent to test and training data\n",
    "    test_df = df.loc[test_indices]\n",
    "    train_df = df.drop(test_indices)\n",
    "\n",
    "    return train_df , test_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_combined = pd.concat([df1,df2],ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "workclass_dict = {\n",
    "    'Federal-gov': 1,\n",
    "    'Local-gov': 2,\n",
    "    'Never-worked': 3,\n",
    "    'Private': 4,\n",
    "    'Self-emp-inc': 5,\n",
    "    'Self-emp-not-inc': 6,\n",
    "    'State-gov': 7,\n",
    "    'Without-pay': 8\n",
    "}\n",
    "\n",
    "education_dict = {\n",
    "    '10th': 1,\n",
    "    '11th': 2,\n",
    "    '12th': 3,\n",
    "    '1st-4th': 4,\n",
    "    '5th-6th': 5,\n",
    "    '7th-8th': 6,\n",
    "    '9th': 7,\n",
    "    'Assoc-acdm': 8,\n",
    "    'Assoc-voc': 9,\n",
    "    'Bachelors': 10,\n",
    "    'Doctorate': 11,\n",
    "    'HS-grad': 12,\n",
    "    'Masters': 13,\n",
    "    'Preschool': 14,\n",
    "    'Prof-school': 15,\n",
    "    'Some-college': 16\n",
    "}\n",
    "\n",
    "marital_status_dict = {\n",
    "    'Divorced': 1,\n",
    "    'Married-AF-spouse': 2,\n",
    "    'Married-civ-spouse': 3,\n",
    "    'Married-spouse-absent': 4,\n",
    "    'Never-married': 5,\n",
    "    'Separated': 6,\n",
    "    'Widowed': 7\n",
    "}\n",
    "\n",
    "occupation_dict = {\n",
    "    'Adm-clerical': 1,\n",
    "    'Armed-Forces': 2,\n",
    "    'Craft-repair': 3,\n",
    "    'Exec-managerial': 4,\n",
    "    'Farming-fishing': 5,\n",
    "    'Handlers-cleaners': 6,\n",
    "    'Machine-op-inspct': 7,\n",
    "    'Other-service': 8,\n",
    "    'Priv-house-serv': 9,\n",
    "    'Prof-specialty': 10,\n",
    "    'Protective-serv': 11,\n",
    "    'Sales': 12,\n",
    "    'Tech-support': 13,\n",
    "    'Transport-moving': 14\n",
    "}\n",
    "\n",
    "relationship_dict = {\n",
    "    'Husband': 1,\n",
    "    'Not-in-family': 2,\n",
    "    'Other-relative': 3,\n",
    "    'Own-child': 4,\n",
    "    'Unmarried': 5,\n",
    "    'Wife': 6\n",
    "}\n",
    "\n",
    "race_dict = {\n",
    "    'Amer-Indian-Eskimo': 1,\n",
    "    'Asian-Pac-Islander': 2,\n",
    "    'Black': 3,\n",
    "    'Other': 4,\n",
    "    'White': 5\n",
    "}\n",
    "\n",
    "sex_dict = {\n",
    "    'Female': 1,\n",
    "    'Male': 2\n",
    "}\n",
    "\n",
    "native_countr_dict = {\n",
    "    'Cambodia': 1,\n",
    "    'Canada': 2,\n",
    "    'China': 3,\n",
    "    'Columbia': 4,\n",
    "    'Cuba': 5,\n",
    "    'Dominican-Republic': 6,\n",
    "    'Ecuador': 7,\n",
    "    'El-Salvador': 8,\n",
    "    'England': 9,\n",
    "    'France': 10,\n",
    "    'Germany': 11,\n",
    "    'Greece': 12,\n",
    "    'Guatemala': 13,\n",
    "    'Haiti': 14,\n",
    "    'Holand-Netherlands': 15,\n",
    "    'Honduras': 16,\n",
    "    'Hong': 17,\n",
    "    'Hungary': 18,\n",
    "    'India': 19,\n",
    "    'Iran': 20,\n",
    "    'Ireland': 21,\n",
    "    'Italy': 22,\n",
    "    'Jamaica': 23,\n",
    "    'Japan': 24,\n",
    "    'Laos': 25,\n",
    "    'Mexico': 26,\n",
    "    'Nicaragua': 27,\n",
    "    'Outlying-US(Guam-USVI-etc)': 28,\n",
    "    'Peru': 29,\n",
    "    'Philippines': 30,\n",
    "    'Poland': 31,\n",
    "    'Portugal': 32,\n",
    "    'Puerto-Rico': 33,\n",
    "    'Scotland': 34,\n",
    "    'South': 35,\n",
    "    'Taiwan': 36,\n",
    "    'Thailand': 37,\n",
    "    'Trinadad&Tobago': 38,\n",
    "    'United-States': 39,\n",
    "    'Vietnam': 40,\n",
    "    'Yugoslavia': 41\n",
    "}\n",
    "\n",
    "label_dict = {\n",
    "    '<=50K': 0,\n",
    "    '>50K': 1\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_combined.workclass = df_combined.workclass.map(workclass_dict)\n",
    "\n",
    "df_combined.education = df_combined.education.map(education_dict)\n",
    "\n",
    "df_combined.marital_status = df_combined.marital_status.map(marital_status_dict)\n",
    "\n",
    "df_combined.occupation = df_combined.occupation.map(occupation_dict)\n",
    "\n",
    "df_combined.relationship = df_combined.relationship.map(relationship_dict)\n",
    "\n",
    "df_combined.race = df_combined.race.map(race_dict)\n",
    "\n",
    "df_combined.sex = df_combined.sex.map(sex_dict)\n",
    "\n",
    "df_combined.native_countr = df_combined.native_countr.map(native_countr_dict)\n",
    "\n",
    "df_combined.label = df_combined.label.map(label_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_combined.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train , df_test = train_test_split(df_combined , 0.33)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test = df_test.label.values\n",
    "\n",
    "df_test = df_test.drop('label',axis = 1)\n",
    "\n",
    "x_test = df_test.values\n",
    "\n",
    "y_train = df_train.label.values\n",
    "\n",
    "df_train = df_train.drop('label',axis =1)\n",
    "\n",
    "x_train = df_train.values\n",
    "\n",
    "x_train = x_train.T\n",
    "x_test = x_test.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_data(data):\n",
    "    max_row = np.amax(data,axis=1)\n",
    "    min_row = np.amin(data,axis=1)\n",
    "    diff = max_row-min_row\n",
    "    diff = diff.reshape(diff.shape[0],1)\n",
    "    max_row = max_row.reshape(max_row.shape[0],1)\n",
    "    min_row = min_row.reshape(min_row.shape[0],1)\n",
    "    diff = diff.reshape(diff.shape[0],1)\n",
    "    data = np.divide((data-min_row),diff)\n",
    "\n",
    "    return(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_test = normalize_data(x_test)\n",
    "x_train = normalize_data(x_train)\n",
    "y_test =  y_test.reshape(1,y_test.shape[0])\n",
    "y_train =  y_train.reshape(1,y_train.shape[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m_train = x_train.shape[1]\n",
    "m_test = x_test.shape[1]\n",
    "\n",
    "print (\"Number of training examples: m_train = \" + str(m_train))\n",
    "print (\"Number of testing examples: m_test = \" + str(m_test))\n",
    "\n",
    "print (\"train_set_x shape: \" + str(x_train.shape))\n",
    "print (\"train_set_y shape: \" + str(y_train.shape))\n",
    "print (\"test_set_x shape: \" + str(x_test.shape))\n",
    "print (\"test_set_y shape: \" + str(y_test.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def initialize_parameters_deep(layer_dims):\n",
    "\n",
    "    parameters = {}\n",
    "    L = len(layer_dims) # number of layers in the network\n",
    "\n",
    "    for l in range(1, L):\n",
    "\n",
    "        parameters['W'+ str(l)] = np.random.randn(layer_dims[l],layer_dims[l-1])*0.01\n",
    "        parameters['b'+ str(l)] = np.zeros((layer_dims[l],1))\n",
    "\n",
    "        assert(parameters['W' + str(l)].shape == (layer_dims[l], layer_dims[l - 1]))\n",
    "        assert(parameters['b' + str(l)].shape == (layer_dims[l], 1))\n",
    "\n",
    "    return parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid(Z):\n",
    "\n",
    "    A = 1/(1+np.exp(-Z))\n",
    "    cache = Z\n",
    "\n",
    "    return A, cache"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def relu(Z):\n",
    "\n",
    "    A = np.maximum(0,Z)\n",
    "    assert(A.shape == Z.shape)\n",
    "\n",
    "    cache = Z\n",
    "    return A, cache\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tanh_(Z):\n",
    "\n",
    "    A = np.tanh(Z)\n",
    "    cache = Z\n",
    "\n",
    "    return A,cache "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tanh_backward(dA,cache):\n",
    "\n",
    "    Z = cache\n",
    "    dZ = dA*(1-np.square(np.tanh(Z)))\n",
    "\n",
    "    return dZ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def relu_backward(dA, cache):\n",
    "\n",
    "    Z = cache\n",
    "    dZ = np.array(dA, copy=True) # just converting dz to a correct object\n",
    "\n",
    "    # When z <= 0,setting dz to 0 as well.\n",
    "    dZ[Z <= 0] = 0\n",
    "    assert (dZ.shape == Z.shape)\n",
    "    return dZ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid_backward(dA, cache):\n",
    "\n",
    "    Z = cache\n",
    "    s = 1/(1+np.exp(-Z))\n",
    "    dZ = dA * s * (1-s)\n",
    "\n",
    "    assert (dZ.shape == Z.shape)\n",
    "    return dZ\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def linear_forward(A, W, b):\n",
    "\n",
    "    Z = np.dot(W,A) + b\n",
    "    cache = (A, W, b)\n",
    "\n",
    "    return Z, cache"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def linear_activation_forward(A_prev, W, b, activation):\n",
    "\n",
    "    if activation == \"sigmoid\":\n",
    "\n",
    "        Z , linear_cache = linear_forward(A_prev,W,b)\n",
    "        A , activation_cache = sigmoid(Z)\n",
    "\n",
    "    elif activation == \"relu\":\n",
    "\n",
    "        Z , linear_cache = linear_forward(A_prev,W,b)\n",
    "        A , activation_cache = relu(Z)\n",
    "\n",
    "    elif activation == \"tanh\":\n",
    "        Z, linear_cache = linear_forward(A_prev,W,b)\n",
    "        A , activation_cache = tanh_(Z)\n",
    "\n",
    "    cache = (linear_cache, activation_cache)\n",
    "\n",
    "    return A, cache"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def L_model_forward(X, parameters):\n",
    "\n",
    "    caches = [] #will contain the list of caches\n",
    "    A = X #for the input layer\n",
    "    L = len(parameters) // 2 #Since we have W and b(bias) we divide by 2\n",
    "\n",
    "    for l in range(1, L):\n",
    "        A_prev = A\n",
    "\n",
    "        A , cache = linear_activation_forward(A_prev,parameters['W'+str(l)],parameters['b'+str(l)],activation = \"relu\")\n",
    "        caches.append(cache)\n",
    "\n",
    "    AL , cache = linear_activation_forward(A,parameters['W'+str(L)],parameters['b'+str(L)],activation=\"sigmoid\")\n",
    "    caches.append(cache)\n",
    "\n",
    "    return AL, caches\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_cost(AL, Y):\n",
    "\n",
    "    m = Y.shape[1]\n",
    "    cost = (-1/m)*np.sum(Y*np.log(AL)+(1-Y)*np.log(1-AL))\n",
    "    cost = np.squeeze(cost)\n",
    "\n",
    "    return cost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def linear_backward(dZ, cache):\n",
    "\n",
    "    A_prev, W, b = cache\n",
    "    m = A_prev.shape[1]\n",
    "\n",
    "    dW = (1/m)*np.dot(dZ,A_prev.T)\n",
    "    db = (1/m)*np.sum(dZ, axis =1,keepdims = True)\n",
    "    dA_prev = np.dot(W.T,dZ)\n",
    "\n",
    "    return dA_prev, dW, db"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def linear_activation_backward(dA, cache, activation):\n",
    "\n",
    "    linear_cache, activation_cache = cache\n",
    "\n",
    "    if activation == \"relu\":\n",
    "\n",
    "        dZ = relu_backward(dA,activation_cache)\n",
    "        dA_prev,dW,db = linear_backward(dZ,linear_cache)\n",
    "        # YOUR CODE ENDS HERE\n",
    "\n",
    "    elif activation == \"sigmoid\":\n",
    "        dZ = sigmoid_backward(dA,activation_cache)\n",
    "        dA_prev,dW,db = linear_backward(dZ,linear_cache)\n",
    "\n",
    "    elif activation == \"tanh\":\n",
    "        dZ = tanh_backward(dA,activation_cache)\n",
    "        dA_prev,dW,db = linear_backward(dZ,linear_cache)\n",
    "\n",
    "    return dA_prev, dW, db"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def L_model_backward(AL, Y, caches):\n",
    "    \n",
    "    grads = {}\n",
    "    L = len(caches) # the number of layers\n",
    "    m = AL.shape[1]\n",
    "    Y = Y.reshape(AL.shape) # after this line, Y is the same shape as AL\n",
    "\n",
    "    dAL = -( np.divide(Y,AL) - np.divide(1-Y,1-AL) )\n",
    "\n",
    "    current_cache = caches[L-1]\n",
    "    dA_prev_temp,dW_temp,db_temp = linear_activation_backward(dAL, current_cache , 'sigmoid') \n",
    "    grads[\"dA\"+str(L-1)]= dA_prev_temp\n",
    "    grads[\"dW\"+str(L)]= dW_temp\n",
    "    grads[\"db\"+str(L)]= db_temp\n",
    "\n",
    "    for l in reversed(range(L-1)):\n",
    "\n",
    "        current_cache = caches[l]\n",
    "        dA_prev_temp,dW_temp,db_temp = linear_activation_backward(grads[\"dA\"+str(l+1)], current_cache , 'relu')\n",
    "        grads[\"dA\"+str(l)]= dA_prev_temp\n",
    "        grads[\"dW\"+str(l+1)]= dW_temp\n",
    "        grads[\"db\"+str(l+1)]= db_temp\n",
    "\n",
    "    return grads"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_parameters(params, grads, learning_rate):\n",
    "\n",
    "    parameters = params.copy()\n",
    "    L = len(parameters) // 2 # number of layers in the neural network\n",
    "\n",
    "    for l in range(L):\n",
    "\n",
    "        parameters[\"W\" + str(l+1)] = parameters[\"W\"+str(l+1)] - learning_rate*grads[\"dW\"+str(l+1)]\n",
    "        parameters[\"b\" + str(l+1)] = parameters[\"b\"+str(l+1)] - learning_rate*grads[\"db\"+str(l+1)]\n",
    "\n",
    "    return parameters\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def L_layer_model(X, Y, layers_dims, learning_rate = 1, num_iterations = 3000, print_cost=False):\n",
    "\n",
    "    costs = [] \n",
    "\n",
    "    parameters = initialize_parameters_deep(layers_dims)\n",
    "\n",
    "    for i in range(0, num_iterations):\n",
    "\n",
    "        AL , caches = L_model_forward(X, parameters)\n",
    "\n",
    "        cost = compute_cost(AL, Y)\n",
    "\n",
    "        grads = L_model_backward(AL, Y, caches)\n",
    "\n",
    "        parameters = update_parameters(parameters, grads, learning_rate)\n",
    "\n",
    "        # Print the cost every 100 iterations\n",
    "        if print_cost and i % 1000 == 0 or i == num_iterations - 1:\n",
    "            print(\"Cost after iteration {}: {}\".format(i, np.squeeze(cost)))\n",
    "        if i % 1000 == 0 or i == num_iterations:\n",
    "            costs.append(cost)\n",
    "\n",
    "    return parameters, costs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(X, y, parameters):\n",
    "\n",
    "    m = X.shape[1]\n",
    "    n = len(parameters) // 2 \n",
    "    p = np.zeros((1,m))\n",
    "\n",
    "\n",
    "    probas, caches = L_model_forward(X, parameters)\n",
    "\n",
    "    for i in range(0, probas.shape[1]):\n",
    "        if probas[0,i] > 0.5:\n",
    "            p[0,i] = 1\n",
    "        else:\n",
    "            p[0,i] = 0\n",
    "\n",
    "    # print(\"Accuracy: \"  + str(np.sum((p == y)/m)))\n",
    "\n",
    "    return p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "layer_single_hidden_dims = [14,7,1]\n",
    "layer_double_hidden_dims = [14,11,7,1]\n",
    "layer_triple_hidden_dims = [14,10,6,4,1]\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For Single Hidden Layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "layers_dims = layer_single_hidden_dims\n",
    "parameters_1, costs_1 = L_layer_model(x_train, y_train, layers_dims,learning_rate = 3, num_iterations = 10000, print_cost = False)\n",
    "print(costs_1)\n",
    "pred_train1 = predict(x_train, y_train, parameters_1)\n",
    "pred_test1 = predict(x_test, y_test,parameters_1)\n",
    "acc_train1 = np.sum((pred_train1 == y_train)/y_train.shape[1])\n",
    "acc_test1 = np.sum((pred_test1 == y_test)/y_test.shape[1])\n",
    "print(\"Training accuracy for 1 hidden layer\",np.sum((pred_train1 == y_train)/y_train.shape[1]))\n",
    "print(\"Test accuracy for 1 hidden layer\",np.sum(np.sum((pred_test1 == y_test)/y_test.shape[1])))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For Two Hidden Layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "layers_dims = layer_double_hidden_dims\n",
    "parameters_2, costs_2 = L_layer_model(x_train, y_train, layers_dims,learning_rate = 3, num_iterations = 10000, print_cost = False)\n",
    "print(costs_2)\n",
    "pred_train2 = predict(x_train, y_train, parameters_2)\n",
    "pred_test2 = predict(x_test, y_test,parameters_2)\n",
    "acc_train2 = np.sum((pred_train2 == y_train)/y_train.shape[1])\n",
    "acc_test2 = np.sum((pred_test2 == y_test)/y_test.shape[1])\n",
    "print(\"Training accuracy for 2 hidden layer\",np.sum((pred_train2 == y_train)/y_train.shape[1]))\n",
    "print(\"Test accuracy for 2 hidden layer\",np.sum(np.sum((pred_test2 == y_test)/y_test.shape[1])))\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For Three Hidden Layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "layers_dims = layer_triple_hidden_dims\n",
    "parameters_3, costs_3 = L_layer_model(x_train, y_train, layers_dims,learning_rate =3, num_iterations = 10000, print_cost = False)\n",
    "print(costs_3)\n",
    "pred_train3 = predict(x_train, y_train, parameters_3)\n",
    "pred_test3 = predict(x_test, y_test,parameters_3)\n",
    "acc_train3 = np.sum((pred_train3 == y_train)/y_train.shape[1])\n",
    "acc_test3 = np.sum((pred_test3 == y_test)/y_test.shape[1])\n",
    "print(\"Training accuracy for 3 hidden layer\",np.sum((pred_train3 == y_train)/y_train.shape[1]))\n",
    "print(\"Test accuracy for 3 hidden layer\",np.sum(np.sum((pred_test3 == y_test)/y_test.shape[1])))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# np.sum((pred_test1 == y_test)/y_test.shape[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cost after iteration 9999: 0.3853412494985926\n",
      "[0.6920383234986953, 0.4035053465788617, 0.39744958628845545, 0.39418526006856147, 0.3918465211091589, 0.390062844463366, 0.3886686780666483, 0.38756080203736204, 0.38666823407917167, 0.3859404386929294]\n",
      "Training accuracy for 0 hidden layer 0.8226378193374896\n",
      "Test accuracy for 0 hidden layer 0.8251023700210942\n"
     ]
    }
   ],
   "source": [
    "layer_new = [14,1]\n",
    "layers_dims = layer_new\n",
    "parameters_4, costs_4 = L_layer_model(x_train, y_train, layers_dims,learning_rate =1.5, num_iterations = 10000, print_cost = False)\n",
    "print(costs_4)\n",
    "pred_train4 = predict(x_train, y_train, parameters_4)\n",
    "pred_test4 = predict(x_test, y_test,parameters_4)\n",
    "acc_train4 = np.sum((pred_train4 == y_train)/y_train.shape[1])\n",
    "acc_test4 = np.sum((pred_test4 == y_test)/y_test.shape[1])\n",
    "print(\"Training accuracy for 0 hidden layer\",acc_train4)\n",
    "print(\"Test accuracy for 0 hidden layer\",acc_test4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
